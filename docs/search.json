[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ABCD Demo Analysis",
    "section": "",
    "text": "Follow along at\n\n\n\nhttps://ajbarrows.github.io/abcd-start/"
  },
  {
    "objectID": "index.html#load-necessary-libraries",
    "href": "index.html#load-necessary-libraries",
    "title": "ABCD Demo Analysis",
    "section": "Load necessary libraries",
    "text": "Load necessary libraries\n\nRPython\n\n\n\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(lmerTest)\n\nlibrary(ggplot2)\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "index.html#read-in-curated-dataset",
    "href": "index.html#read-in-curated-dataset",
    "title": "ABCD Demo Analysis",
    "section": "Read in curated dataset",
    "text": "Read in curated dataset\n\nRPython\n\n\n\n# watch out for periods in directory names...\n\nfpath &lt;- '../data/02_intermediate/dataset.csv/dataset.csv' # you'll need to adjust file directories\ndf &lt;- read.csv(\n  fpath,\n  na.strings = c(\"NA\", ' ', 999, 777) # blank spaces are missing data\n  )\nhead(df)\n\n\n\n\n# watch out for periods in directory names...\n\nfpath = '../data/02_intermediate/dataset.csv/dataset.csv' # you'll need to adjust file directories\n\ndf = pd.read_csv(fpath, na_values=['NA', ' ', 999, 777]) # blank spaces are missing data\ndf.head()\n\n\n\n\nBut… you’re not always going to have a curated dataset…"
  },
  {
    "objectID": "index.html#sort-out-variable-types",
    "href": "index.html#sort-out-variable-types",
    "title": "ABCD Demo Analysis",
    "section": "Sort out variable types",
    "text": "Sort out variable types\n\nRPython\n\n\n\n# sort out variables, both to keep organized and arrange data types\npredictors &lt;- c(\n  'mr_y_smri__vol__aseg__ag__lh_sum', # left amygdala vol\n  'mr_y_smri__vol__aseg__ag__rh_sum' # right amygdala vol\n)\n\ncovariates &lt;- c(\n  'ab_g_dyn__visit_age', # age\n  'ab_p_demo__saab_001', # sex\n  'ab_p_demo__income__hhold_001', # household income\n  # 'ph_y_pds__f_categ', # female puberty scale\n  # 'ph_y_pds__m_categ', # male puberty scale\n  'mr_y_adm__info__dev_serial' # scanner\n)\n\ntargets &lt;- c(\n  \"su_y_lowuse__isip_001\",\n  \"su_y_lowuse__isip_001__l\" # we'll sort this out later\n)\n\nid_vars &lt;- c(\n  'participant_id',\n  'session_id'\n)\n\npredictor_timepoint &lt;- 'ses-00A' # baseline\ntarget_timepoint &lt;- 'ses-03A' # Year 3\n\ncumulative_timepoints &lt;- c(\n  'ses-00A',\n  'ses-01A',\n  'ses-02A',\n  'ses-03A'\n)\n\nall_vars &lt;- c(\n  id_vars,\n  predictors,\n  covariates,\n  targets\n)\n\n# peel off categorical variables\ncategorical_list &lt;- c(\n  'session_id',\n  'ab_p_demo__saab_001',\n  'ab_p_demo__income__hhold_001',\n  'mr_y_adm__info__dev_serial'\n  # 'ph_y_pds__f_categ',\n  # 'ph_y_pds__m_categ'\n)\n\n\n\n\n# sort out variables, both to keep organized and arrange data types\npredictors = [\n    'mr_y_smri__vol__aseg__ag__lh_sum', # left amygdala vol\n    'mr_y_smri__vol__aseg__ag__rh_sum' # right amygdala vol\n]\n\ncovariates = [\n    'ab_g_dyn__visit_age', # age\n    'ab_p_demo__saab_001', # sex\n    'ab_p_demo__income__hhold_001', # household income\n    # 'ph_y_pds__f_categ', # female puberty scale\n    # 'ph_y_pds__m_categ', # male puberty scale\n    'mr_y_adm__info__dev_serial' # scanner\n]\n\ntargets = [\n    \"su_y_lowuse__isip_001\",\n    \"su_y_lowuse__isip_001__l\" # we'll sort this out later\n]\n\nid_vars = [\n    'participant_id',\n    'session_id'\n]\n\npredictor_timepoint = 'ses-00A' # baseline\ntarget_timepoint = 'ses-03A' # Year 3\n\ncumulative_timepoints = [\n    'ses-00A',\n    'ses-01A',\n    'ses-02A',\n    'ses-03A'\n]\n\nall_vars = id_vars + predictors + covariates + targets\n\n# peel off categorical variables\ncategorical_list = [\n    'session_id',\n    'ab_p_demo__saab_001',\n    'ab_p_demo__income__hhold_001',\n    'mr_y_adm__info__dev_serial'\n    # 'ph_y_pds__f_categ',\n    # 'ph_y_pds__m_categ'\n]\n\n\n\n\nNeed to do a few things:\n\nMake a subset of the dataset using all_vars\nMake sure categorical variables are represented as such using categorical_list\nConstruct a predictor dataset of baseline variables\nConstruct a target dataset of Year 3 variables\nCombine longitudinal variables into one target\n\n\nRPython\n\n\n\nsubset &lt;- df %&gt;% \n  select(all_of(all_vars)) %&gt;%\n  mutate(across(all_of(categorical_list), as.factor))\n\n# make predictor (baseline) dataset\nX &lt;- subset %&gt;% \n  filter(session_id == predictor_timepoint) %&gt;%\n  select(all_of(c(id_vars, predictors, covariates)))\n\n# make target (Year 3) dataset, filter for cumulative timepoints\ny &lt;- subset %&gt;%\n  filter(session_id %in% cumulative_timepoints) %&gt;%\n  select(all_of(c(id_vars, targets)))\n\n\n\n\nsubset = df[all_vars].copy()\nsubset[categorical_list] = subset[categorical_list].astype('category')\n\n# make predictor (baseline) dataset\nX = subset[subset['session_id'] == predictor_timepoint][id_vars + predictors + covariates]\n\n# make target (Year 3) dataset, filter for cumulative timepoints\ny = subset[subset['session_id'].isin(cumulative_timepoints)][id_vars + targets]\ny = y[y['session_id'].isin(cumulative_timepoints)]\n\n\n\n\nBaseline “sips” and longitudinal sips are recorded in different variables. We’ll add them together.\n\nRPython\n\n\n\ny &lt;- y %&gt;%\n  rowwise() %&gt;%\n  mutate(sips_combined = sum(c_across(where(is.numeric)), na.rm = TRUE)) %&gt;%\n  select(all_of(id_vars), sips_combined)\ny\n\n\n\n\ny['sips_combined'] = np.sum(y[targets], axis=1)\ny = y.drop(targets, axis=1)\ny\n\n\n\n\nThen we need to pivot this new variable to make a cumulative sips variable.\n\nRPython\n\n\n\ny_pivot &lt;- y %&gt;%\n  tidyr::pivot_wider(id_cols = 'participant_id',\n                     names_from = 'session_id',\n                     values_from = 'sips_combined')\ny_pivot\n\n\n\n\ny_pivot = pd.pivot(y, \n                    index='participant_id', \n                    columns='session_id', \n                    values='sips_combined')\ny_pivot\n\n\n\n\nAdd together values from baseline through year 3\n\nRPython\n\n\n\ny &lt;- y_pivot %&gt;% \n  rowwise() %&gt;% \n  mutate(sips = sum(c_across(where(is.numeric)), na.rm = TRUE)) %&gt;%\n  select(participant_id, sips)\n\ny\n\n\n\n\ny_pivot['sips'] = np.sum(y_pivot[cumulative_timepoints], axis=1)\ny = y_pivot.drop(cumulative_timepoints, axis=1)\ny"
  },
  {
    "objectID": "index.html#put-datasets-back-together",
    "href": "index.html#put-datasets-back-together",
    "title": "ABCD Demo Analysis",
    "section": "Put datasets back together",
    "text": "Put datasets back together\n\nRPython\n\n\n\ndata &lt;- cbind(X, y)  %&gt;% tidyr::drop_na() # drop all missing rows\nwrite.csv(data, \"../data/03_model_input/alcohol_model_input.csv\") # save to disk\n\n\n\n\ndata = pd.concat([X.set_index('participant_id'), y], axis=1).reset_index()\ndata = data.dropna()\n\ndata.to_csv(\"../data/03_model_input/alcohol_model_input.csv\", index=False)"
  },
  {
    "objectID": "index.html#fit-a-basic-linear-mixed-effects-model",
    "href": "index.html#fit-a-basic-linear-mixed-effects-model",
    "title": "ABCD Demo Analysis",
    "section": "Fit a basic linear mixed effects model:",
    "text": "Fit a basic linear mixed effects model:\n\nRPython\n\n\n\nfm1 &lt;- sips ~ \n  mr_y_smri__vol__aseg__ag__lh_sum + \n  mr_y_smri__vol__aseg__ag__rh_sum +\n  ab_p_demo__saab_001 +\n  ab_g_dyn__visit_age +\n  ab_p_demo__income__hhold_001 +\n  (1 | mr_y_adm__info__dev_serial)\n\nfit_1 &lt;- lmer(fm1, data = data)\nsummary(fit_1)\n\n\n\n\nfm1 = \"\"\"\nsips ~ mr_y_smri__vol__aseg__ag__lh_sum + \n    mr_y_smri__vol__aseg__ag__rh_sum + \n    ab_p_demo__saab_001 + \n    ab_g_dyn__visit_age + \n    ab_p_demo__income__hhold_001\n\"\"\"\n\n# Fit the model\nfit_1 = smf.mixedlm(fm1, data, groups=data['mr_y_adm__info__dev_serial'])\nfit_1 = fit_1.fit()\nprint(fit_1.summary())"
  },
  {
    "objectID": "index.html#plot-model-fit",
    "href": "index.html#plot-model-fit",
    "title": "ABCD Demo Analysis",
    "section": "Plot model fit",
    "text": "Plot model fit\n\nRPython\n\n\n\npredictions = predict(fit_1)\n\n\nprediction_df &lt;- data.frame(\n  predicted_sips = predictions,\n  actual_sips = data$sips,\n  amygdala_vol_left = data$mr_y_smri__vol__aseg__ag__lh_sum, \n  amygdala_vol_right = data$mr_y_smri__vol__aseg__ag__rh_sum\n)\n\n# ggplot needs long-form data for faceting\nprediction_long &lt;- prediction_df %&gt;%\n  tidyr::pivot_longer(cols=c(amygdala_vol_left, amygdala_vol_right),\n                      names_to = 'hemisphere',\n                      values_to = 'volume')\n\n\n\n\npredictions = fit_1.predict(data)\nprediction_df = pd.DataFrame(\n    {\n        'predicted_sips': predictions,\n        'actual_sips': data['sips'],\n        'amygdala_vol_left': data['mr_y_smri__vol__aseg__ag__lh_sum'],\n        'amygdala_vol_right': data['mr_y_smri__vol__aseg__ag__rh_sum'],\n    }\n)\n\n\n\n\n\nRPython\n\n\n\nggplot(prediction_long, aes(x = volume)) +\n  geom_point(aes(y = actual_sips), color = 'blue') +\n  geom_line(aes(y = predicted_sips), color = 'red') +\n  facet_wrap(~hemisphere) +\n  theme_bw()\n\n\n\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\nfor ax, hemisphere in zip(axs, ['left', 'right']):\n\n    ax.scatter(\n        prediction_df[f'amygdala_vol_{hemisphere}'], \n        prediction_df['actual_sips'], \n        label='Actual',\n        color='blue'\n    )\n\n    ax.set_title(f'Sips vs. {hemisphere.capitalize()} Amygdala Volume')\n    ax.set_xlabel(f'{hemisphere.capitalize()} Amygdala Volume')\n    ax.set_ylabel('Sips')\n\n    ax.plot(\n        prediction_df[f'amygdala_vol_{hemisphere}'], \n        prediction_df['predicted_sips'], \n        label='Predicted',\n        color='red'\n    )\n\nplt.legend()"
  }
]