[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ABCD Demo Analysis",
    "section": "",
    "text": "Follow along at\n\n\n\nhttps://ajbarrows.github.io/abcd-start/"
  },
  {
    "objectID": "index.html#load-necessary-libraries",
    "href": "index.html#load-necessary-libraries",
    "title": "ABCD Demo Analysis",
    "section": "Load necessary libraries",
    "text": "Load necessary libraries\n\nRPython\n\n\n\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(lmerTest)\n\nlibrary(ggplot2)\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "index.html#read-in-curated-dataset",
    "href": "index.html#read-in-curated-dataset",
    "title": "ABCD Demo Analysis",
    "section": "Read in curated dataset",
    "text": "Read in curated dataset\n\nRPython\n\n\n\n# watch out for periods in directory names...\n\nfpath &lt;- '../data/02_intermediate/dataset.csv/dataset.csv' # you'll need to adjust file directories\ndf &lt;- read.csv(\n  fpath,\n  na.strings = c(\"NA\", ' ', 999, 777) # blank spaces are missing data\n  )\nhead(df)\n\n\n\n\n# watch out for periods in directory names...\n\nfpath = '../data/02_intermediate/dataset.csv/dataset.csv' # you'll need to adjust file directories\n\ndf = pd.read_csv(fpath, na_values=['NA', ' ', 999, 777]) # blank spaces are missing data\ndf.head()\n\n\n\n\nBut… you’re not always going to have a curated dataset…"
  },
  {
    "objectID": "index.html#sort-out-variable-types",
    "href": "index.html#sort-out-variable-types",
    "title": "ABCD Demo Analysis",
    "section": "Sort out variable types",
    "text": "Sort out variable types\n\nRPython\n\n\n\n# sort out variables, both to keep organized and arrange data types\npredictors &lt;- c(\n  'mr_y_smri__vol__aseg__ag__lh_sum', # left amygdala vol\n  'mr_y_smri__vol__aseg__ag__rh_sum' # right amygdala vol\n)\n\ncovariates &lt;- c(\n  'ab_g_dyn__visit_age', # age\n  'ab_p_demo__saab_001', # sex\n  'ab_p_demo__income__hhold_001', # household income\n  # 'ph_y_pds__f_categ', # female puberty scale\n  # 'ph_y_pds__m_categ', # male puberty scale\n  'mr_y_adm__info__dev_serial' # scanner\n)\n\ntargets &lt;- c(\n  \"su_y_lowuse__isip_001\",\n  \"su_y_lowuse__isip_001__l\" # we'll sort this out later\n)\n\nid_vars &lt;- c(\n  'participant_id',\n  'session_id'\n)\n\npredictor_timepoint &lt;- 'ses-00A' # baseline\ntarget_timepoint &lt;- 'ses-03A' # Year 3\n\ncumulative_timepoints &lt;- c(\n  'ses-00A',\n  'ses-01A',\n  'ses-02A',\n  'ses-03A'\n)\n\nall_vars &lt;- c(\n  id_vars,\n  predictors,\n  covariates,\n  targets\n)\n\n# peel off categorical variables\ncategorical_list &lt;- c(\n  'session_id',\n  'ab_p_demo__saab_001',\n  'ab_p_demo__income__hhold_001',\n  'mr_y_adm__info__dev_serial'\n  # 'ph_y_pds__f_categ',\n  # 'ph_y_pds__m_categ'\n)\n\n\n\n\n# sort out variables, both to keep organized and arrange data types\npredictors = [\n    'mr_y_smri__vol__aseg__ag__lh_sum', # left amygdala vol\n    'mr_y_smri__vol__aseg__ag__rh_sum' # right amygdala vol\n]\n\ncovariates = [\n    'ab_g_dyn__visit_age', # age\n    'ab_p_demo__saab_001', # sex\n    'ab_p_demo__income__hhold_001', # household income\n    # 'ph_y_pds__f_categ', # female puberty scale\n    # 'ph_y_pds__m_categ', # male puberty scale\n    'mr_y_adm__info__dev_serial' # scanner\n]\n\ntargets = [\n    \"su_y_lowuse__isip_001\",\n    \"su_y_lowuse__isip_001__l\" # we'll sort this out later\n]\n\nid_vars = [\n    'participant_id',\n    'session_id'\n]\n\npredictor_timepoint = 'ses-00A' # baseline\ntarget_timepoint = 'ses-03A' # Year 3\n\ncumulative_timepoints = [\n    'ses-00A',\n    'ses-01A',\n    'ses-02A',\n    'ses-03A'\n]\n\nall_vars = id_vars + predictors + covariates + targets\n\n# peel off categorical variables\ncategorical_list = [\n    'session_id',\n    'ab_p_demo__saab_001',\n    'ab_p_demo__income__hhold_001',\n    'mr_y_adm__info__dev_serial'\n    # 'ph_y_pds__f_categ',\n    # 'ph_y_pds__m_categ'\n]\n\n\n\n\nNeed to do a few things:\n\nMake a subset of the dataset using all_vars\nMake sure categorical variables are represented as such using categorical_list\nConstruct a predictor dataset of baseline variables\nConstruct a target dataset of Year 3 variables\nCombine longitudinal variables into one target\n\n\nRPython\n\n\n\nsubset &lt;- df %&gt;% \n  select(all_of(all_vars)) %&gt;%\n  mutate(across(all_of(categorical_list), as.factor))\n\n# make predictor (baseline) dataset\nX &lt;- subset %&gt;% \n  filter(session_id == predictor_timepoint) %&gt;%\n  select(all_of(c(id_vars, predictors, covariates)))\n\n# make target (Year 3) dataset, filter for cumulative timepoints\ny &lt;- subset %&gt;%\n  filter(session_id %in% cumulative_timepoints) %&gt;%\n  select(all_of(c(id_vars, targets)))\n\n\n\n\nsubset = df[all_vars].copy()\nsubset[categorical_list] = subset[categorical_list].astype('category')\n\n# make predictor (baseline) dataset\nX = subset[subset['session_id'] == predictor_timepoint][id_vars + predictors + covariates]\n\n# make target (Year 3) dataset, filter for cumulative timepoints\ny = subset[subset['session_id'].isin(cumulative_timepoints)][id_vars + targets]\ny = y[y['session_id'].isin(cumulative_timepoints)]\n\n\n\n\nBaseline “sips” and longitudinal sips are recorded in different variables. We’ll add them together.\n\nRPython\n\n\n\ny &lt;- y %&gt;%\n  rowwise() %&gt;%\n  mutate(sips_combined = sum(c_across(where(is.numeric)), na.rm = TRUE)) %&gt;%\n  select(all_of(id_vars), sips_combined)\ny\n\n\n\n\ny['sips_combined'] = np.sum(y[targets], axis=1)\ny = y.drop(targets, axis=1)\ny\n\n\n\n\nThen we need to pivot this new variable to make a cumulative sips variable.\n\nRPython\n\n\n\ny_pivot &lt;- y %&gt;%\n  tidyr::pivot_wider(id_cols = 'participant_id',\n                     names_from = 'session_id',\n                     values_from = 'sips_combined')\ny_pivot\n\n\n\n\ny_pivot = pd.pivot(y, \n                    index='participant_id', \n                    columns='session_id', \n                    values='sips_combined')\ny_pivot\n\n\n\n\nAdd together values from baseline through year 3\n\nRPython\n\n\n\ny &lt;- y_pivot %&gt;% \n  rowwise() %&gt;% \n  mutate(year3_sips = sum(c_across(where(is.numeric)), na.rm = TRUE)) %&gt;%\n  select(participant_id, year3_sips)\n\ny\n\n\n\n\ny_pivot['sips'] = np.sum(y_pivot[cumulative_timepoints], axis=1)\ny = y_pivot.drop(cumulative_timepoints, axis=1)\ny"
  },
  {
    "objectID": "index.html#put-datasets-back-together",
    "href": "index.html#put-datasets-back-together",
    "title": "ABCD Demo Analysis",
    "section": "Put datasets back together",
    "text": "Put datasets back together\n\nRPython\n\n\n\ndata &lt;- cbind(X, y)  %&gt;% tidyr::drop_na() # drop all missing rows\nwrite.csv(data, \"../data/03_model_input/alcohol_model_input.csv\") # save to disk\n\n\n\n\ndata = pd.concat([X.set_index('participant_id'), y], axis=1).reset_index()\ndata = data.dropna()\n\ndata.to_csv(\"../data/03_model_input/alcohol_model_input.csv\", index=False)\n\n\n\n\n## Fit a basic linear mixed effects model:\n\nRPython\n\n\n\nfm1 &lt;- year3_sips ~ \n  mr_y_smri__vol__aseg__ag__lh_sum + \n  mr_y_smri__vol__aseg__ag__rh_sum +\n  ab_p_demo__saab_001 +\n  ab_g_dyn__visit_age +\n  ab_p_demo__income__hhold_001 +\n  (1 | mr_y_adm__info__dev_serial)\n\nfit_1 &lt;- lmer(fm1, data = data)\nsummary(fit_1)\n\n\n\n\nfm1 = \"\"\"\nsips ~ mr_y_smri__vol__aseg__ag__lh_sum + \n    mr_y_smri__vol__aseg__ag__rh_sum + \n    ab_p_demo__saab_001 + \n    ab_g_dyn__visit_age + \n    ab_p_demo__income__hhold_001\n\"\"\"\n\n# Fit the model\nfit_1 = smf.mixedlm(fm1, data, groups=data['mr_y_adm__info__dev_serial'])\nfit_1 = fit_1.fit()\nprint(fit_1.summary())"
  }
]